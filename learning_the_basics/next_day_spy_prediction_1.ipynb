{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22285939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import yfinance as yf\n",
    "\n",
    "# https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras\n",
    "\n",
    "#try changing around the optimizer\n",
    "\n",
    "# Reproducability\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2df015aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#units = neurons\n",
    "def load_data(ticker, period, interval, n_steps=50, scale=True, shuffle=True, lookup_step=1, test_size=.2,\n",
    "              feature_columns=['Close', 'Volume', 'Open', 'High', 'Low']):\n",
    "    '''\n",
    "    :param ticker: Ticker you want to load, dtype: str\n",
    "    :param period: Time period you want data from, dtype: str(options in program)\n",
    "    :param interval: Interval for data, dtype:str\n",
    "    :param n_steps: Past sequence len used to predict, default = 50, dtype: int\n",
    "    :param scale: Whether to scale data b/w 0 and 1, default = True, dtype: Bool\n",
    "    :param shuffle: Whether to shuffle data, default = True, dtyper: Bool\n",
    "    :param lookup_step: Future lookup step to predict, default = 1(next day), dtype:int\n",
    "    :param test_size: ratio for test data, default is .2 (20% test data), dtype: float\n",
    "    :param feature_columns: list of features fed into the model, default is OHLCV, dtype: list\n",
    "    :return:\n",
    "    '''\n",
    "    df = yf.download(tickers=ticker, period=period, interval=interval,\n",
    "                     group_by='ticker',\n",
    "                     # adjust all OHLC automatically\n",
    "                     auto_adjust=True, prepost=True, threads=True, proxy=None)\n",
    "\n",
    "    #print(\"removing last day for testing by damian\")\n",
    "    #df = df.iloc[:-16 , :].copy()\n",
    "    #print(df.tail())\n",
    "    \n",
    "    \n",
    "    result = {}\n",
    "    result['df'] = df.copy()\n",
    "\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['Close'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices not available in the dataset\n",
    "    last_sequence = list(sequences) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # reshape X to fit the neural network\n",
    "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
    "    # split the dataset\n",
    "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y,\n",
    "                                                                               test_size=test_size, shuffle=shuffle)\n",
    "    # return the result\n",
    "    return result\n",
    "\n",
    "#Again, this function is flexible too, and you can change the number of layers, dropout rate, the RNN cell, loss, and the optimizer used to compile the model.\n",
    "\n",
    "#The above function constructs an RNN with a dense layer as an output layer with one neuron. This model requires a sequence of features of sequence_length (in this case, we will pass 50 or 100) consecutive time steps (which are days in this dataset) and outputs a single value which indicates the price of the next time step.\n",
    "\n",
    "#It also accepts n_features as an argument, which is the number of features we will pass on each sequence, in our case, we'll pass adjclose, open, high, low and volume columns (i.e 5 features).\n",
    "\n",
    "#You can tweak the default parameters as you wish, n_layers is the number of RNN layers you want to stack, dropout is the dropout rate after each RNN layer, units are the number of RNN cell units (whether it is LSTM, SimpleRNN, or GRU), bidirectional is a boolean that indicates whether to use bidirectional RNNs, experiment with those!\n",
    "\n",
    "\n",
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"adam\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86917d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Function' object has no attribute '_concrete_stateful_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5012\\493697925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"results\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mtensorboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"logs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m history = model.fit(data[\"X_train\"], data[\"y_train\"],\n\u001b[0m\u001b[0;32m     58\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_write_keras_model_train_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2517\u001b[0m                 \u001b[1;31m# graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"function_spec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2519\u001b[1;33m                     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write_keras_model_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Function' object has no attribute '_concrete_stateful_fn'"
     ]
    }
   ],
   "source": [
    "N_STEPS = 70\n",
    "# valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "PERIOD = '2y'\n",
    "# valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "INTERVAL = '1d'\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 1\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.3\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# > model parameters <\n",
    "N_LAYERS = 3\n",
    "#Type of model\n",
    "CELL = LSTM\n",
    "# Number of neurons\n",
    "UNITS = 256\n",
    "# Dropout rate\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "# > training parameters <\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 200\n",
    "ticker = \"SPY\"\n",
    "\n",
    "#save model\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "# folders that store results\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "data = load_data(ticker, PERIOD, INTERVAL, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv()\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "\n",
    "# >> Testing the Model <<\n",
    "\n",
    "data = load_data(ticker, PERIOD, INTERVAL, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
    "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)\n",
    "\n",
    "# evaluate the model\n",
    "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "mean_absolute_error = data[\"column_scaler\"][\"Close\"].inverse_transform([[mae]])[0][0]\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9dc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd683a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a016f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    column_scaler = data[\"column_scaler\"]\n",
    "    # Swap dimensions\n",
    "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    predicted_price = column_scaler[\"Close\"].inverse_transform(prediction)[0][0]\n",
    "    return predicted_price\n",
    "\n",
    "# predict the future price\n",
    "future_price = predict(model, data)\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(model, data):\n",
    "    y_test = data[\"y_test\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_test = np.squeeze(data[\"column_scaler\"][\"Close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "    y_pred = np.squeeze(data[\"column_scaler\"][\"Close\"].inverse_transform(y_pred))\n",
    "    # currently last 200 days\n",
    "    plt.plot(y_test[-200:], c='b')\n",
    "    plt.plot(y_pred[-200:], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()\n",
    "\n",
    "plot_graph(model, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd925e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data):\n",
    "    y_test = data[\"y_test\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_test = np.squeeze(data[\"column_scaler\"][\"Close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "    y_pred = np.squeeze(data[\"column_scaler\"][\"Close\"].inverse_transform(y_pred))\n",
    "    y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
    "    y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(str(LOOKUP_STEP) + \":\", \"Accuracy Score:\", accuracy(model, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f370b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9c0c309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"y_test\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "033ea352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 5, 70)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"X_test\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7edc95b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951, 5, 70)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"X_train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9db713fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"y_train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bb0d986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"df\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e59870c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results\\\\2023-01-07_XLF-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "#model.load_weights(model_path)\n",
    "model_path  #'results\\\\2023-01-07_XLF-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c6d2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "305ff674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "944d45c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_sequence = data[\"last_sequence\"][-70:]\n",
    "last_sequence.shape  # 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4790c739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 70)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86c2c12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 70)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa3fbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_1(ticker, period, interval, n_steps=50, scale=True, shuffle=True, lookup_step=1, test_size=.2,\n",
    "              feature_columns=['Close', 'Volume', 'Open', 'High', 'Low']):\n",
    "    '''\n",
    "    :param ticker: Ticker you want to load, dtype: str\n",
    "    :param period: Time period you want data from, dtype: str(options in program)\n",
    "    :param interval: Interval for data, dtype:str\n",
    "    :param n_steps: Past sequence len used to predict, default = 50, dtype: int\n",
    "    :param scale: Whether to scale data b/w 0 and 1, default = True, dtype: Bool\n",
    "    :param shuffle: Whether to shuffle data, default = True, dtyper: Bool\n",
    "    :param lookup_step: Future lookup step to predict, default = 1(next day), dtype:int\n",
    "    :param test_size: ratio for test data, default is .2 (20% test data), dtype: float\n",
    "    :param feature_columns: list of features fed into the model, default is OHLCV, dtype: list\n",
    "    :return:\n",
    "    '''\n",
    "    df = yf.download(tickers=ticker, period=period, interval=interval,\n",
    "                     group_by='ticker',\n",
    "                     # adjust all OHLC automatically\n",
    "                     auto_adjust=True, prepost=True, threads=True, proxy=None)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aa5d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data1 = load_data_1('SPY', PERIOD, INTERVAL, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f26ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>365.227382</td>\n",
       "      <td>368.917517</td>\n",
       "      <td>365.042872</td>\n",
       "      <td>368.140656</td>\n",
       "      <td>68766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>369.587607</td>\n",
       "      <td>370.461583</td>\n",
       "      <td>366.198508</td>\n",
       "      <td>370.238251</td>\n",
       "      <td>71677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>366.926841</td>\n",
       "      <td>369.577901</td>\n",
       "      <td>366.800594</td>\n",
       "      <td>367.742554</td>\n",
       "      <td>51034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>367.936746</td>\n",
       "      <td>368.878676</td>\n",
       "      <td>365.479857</td>\n",
       "      <td>367.820190</td>\n",
       "      <td>52547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>367.742524</td>\n",
       "      <td>369.849775</td>\n",
       "      <td>366.926811</td>\n",
       "      <td>368.810730</td>\n",
       "      <td>45303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>380.640015</td>\n",
       "      <td>382.579987</td>\n",
       "      <td>378.429993</td>\n",
       "      <td>382.429993</td>\n",
       "      <td>83975100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>384.369995</td>\n",
       "      <td>386.429993</td>\n",
       "      <td>377.829987</td>\n",
       "      <td>380.820007</td>\n",
       "      <td>74850700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>383.179993</td>\n",
       "      <td>385.880005</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>383.760010</td>\n",
       "      <td>85934100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>381.720001</td>\n",
       "      <td>381.839996</td>\n",
       "      <td>378.760010</td>\n",
       "      <td>379.380005</td>\n",
       "      <td>76970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>382.609985</td>\n",
       "      <td>389.250000</td>\n",
       "      <td>379.410004</td>\n",
       "      <td>388.079987</td>\n",
       "      <td>104041300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close     Volume\n",
       "Date                                                                 \n",
       "2021-01-07  365.227382  368.917517  365.042872  368.140656   68766800\n",
       "2021-01-08  369.587607  370.461583  366.198508  370.238251   71677200\n",
       "2021-01-11  366.926841  369.577901  366.800594  367.742554   51034700\n",
       "2021-01-12  367.936746  368.878676  365.479857  367.820190   52547700\n",
       "2021-01-13  367.742524  369.849775  366.926811  368.810730   45303600\n",
       "...                ...         ...         ...         ...        ...\n",
       "2022-12-30  380.640015  382.579987  378.429993  382.429993   83975100\n",
       "2023-01-03  384.369995  386.429993  377.829987  380.820007   74850700\n",
       "2023-01-04  383.179993  385.880005  380.000000  383.760010   85934100\n",
       "2023-01-05  381.720001  381.839996  378.760010  379.380005   76970500\n",
       "2023-01-06  382.609985  389.250000  379.410004  388.079987  104041300\n",
       "\n",
       "[504 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4dcd5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>365.227382</td>\n",
       "      <td>368.917517</td>\n",
       "      <td>365.042872</td>\n",
       "      <td>368.140656</td>\n",
       "      <td>68766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>369.587607</td>\n",
       "      <td>370.461583</td>\n",
       "      <td>366.198508</td>\n",
       "      <td>370.238251</td>\n",
       "      <td>71677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>366.926841</td>\n",
       "      <td>369.577901</td>\n",
       "      <td>366.800594</td>\n",
       "      <td>367.742554</td>\n",
       "      <td>51034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>367.936746</td>\n",
       "      <td>368.878676</td>\n",
       "      <td>365.479857</td>\n",
       "      <td>367.820190</td>\n",
       "      <td>52547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>367.742524</td>\n",
       "      <td>369.849775</td>\n",
       "      <td>366.926811</td>\n",
       "      <td>368.810730</td>\n",
       "      <td>45303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>391.143858</td>\n",
       "      <td>393.831529</td>\n",
       "      <td>390.178291</td>\n",
       "      <td>391.362854</td>\n",
       "      <td>65927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-08</th>\n",
       "      <td>393.333824</td>\n",
       "      <td>395.543648</td>\n",
       "      <td>391.472347</td>\n",
       "      <td>394.428772</td>\n",
       "      <td>60737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09</th>\n",
       "      <td>393.134716</td>\n",
       "      <td>395.802458</td>\n",
       "      <td>391.352889</td>\n",
       "      <td>391.482300</td>\n",
       "      <td>81367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12</th>\n",
       "      <td>392.308501</td>\n",
       "      <td>397.126404</td>\n",
       "      <td>391.611719</td>\n",
       "      <td>397.126404</td>\n",
       "      <td>75405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-13</th>\n",
       "      <td>408.344888</td>\n",
       "      <td>408.613643</td>\n",
       "      <td>397.245861</td>\n",
       "      <td>400.132599</td>\n",
       "      <td>123782500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close     Volume\n",
       "Date                                                                 \n",
       "2021-01-07  365.227382  368.917517  365.042872  368.140656   68766800\n",
       "2021-01-08  369.587607  370.461583  366.198508  370.238251   71677200\n",
       "2021-01-11  366.926841  369.577901  366.800594  367.742554   51034700\n",
       "2021-01-12  367.936746  368.878676  365.479857  367.820190   52547700\n",
       "2021-01-13  367.742524  369.849775  366.926811  368.810730   45303600\n",
       "...                ...         ...         ...         ...        ...\n",
       "2022-12-07  391.143858  393.831529  390.178291  391.362854   65927900\n",
       "2022-12-08  393.333824  395.543648  391.472347  394.428772   60737900\n",
       "2022-12-09  393.134716  395.802458  391.352889  391.482300   81367500\n",
       "2022-12-12  392.308501  397.126404  391.611719  397.126404   75405800\n",
       "2022-12-13  408.344888  408.613643  397.245861  400.132599  123782500\n",
       "\n",
       "[488 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.iloc[:-16 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8c352fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>365.227382</td>\n",
       "      <td>368.917517</td>\n",
       "      <td>365.042872</td>\n",
       "      <td>368.140656</td>\n",
       "      <td>68766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>369.587607</td>\n",
       "      <td>370.461583</td>\n",
       "      <td>366.198508</td>\n",
       "      <td>370.238251</td>\n",
       "      <td>71677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>366.926841</td>\n",
       "      <td>369.577901</td>\n",
       "      <td>366.800594</td>\n",
       "      <td>367.742554</td>\n",
       "      <td>51034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>367.936746</td>\n",
       "      <td>368.878676</td>\n",
       "      <td>365.479857</td>\n",
       "      <td>367.820190</td>\n",
       "      <td>52547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>367.742524</td>\n",
       "      <td>369.849775</td>\n",
       "      <td>366.926811</td>\n",
       "      <td>368.810730</td>\n",
       "      <td>45303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>397.594260</td>\n",
       "      <td>398.161631</td>\n",
       "      <td>389.849824</td>\n",
       "      <td>392.029785</td>\n",
       "      <td>77972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>391.143858</td>\n",
       "      <td>393.831529</td>\n",
       "      <td>390.178291</td>\n",
       "      <td>391.362854</td>\n",
       "      <td>65927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-08</th>\n",
       "      <td>393.333824</td>\n",
       "      <td>395.543648</td>\n",
       "      <td>391.472347</td>\n",
       "      <td>394.428772</td>\n",
       "      <td>60737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09</th>\n",
       "      <td>393.134716</td>\n",
       "      <td>395.802458</td>\n",
       "      <td>391.352889</td>\n",
       "      <td>391.482300</td>\n",
       "      <td>81367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12</th>\n",
       "      <td>392.308501</td>\n",
       "      <td>397.126404</td>\n",
       "      <td>391.611719</td>\n",
       "      <td>397.126404</td>\n",
       "      <td>75405800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume\n",
       "Date                                                                \n",
       "2021-01-07  365.227382  368.917517  365.042872  368.140656  68766800\n",
       "2021-01-08  369.587607  370.461583  366.198508  370.238251  71677200\n",
       "2021-01-11  366.926841  369.577901  366.800594  367.742554  51034700\n",
       "2021-01-12  367.936746  368.878676  365.479857  367.820190  52547700\n",
       "2021-01-13  367.742524  369.849775  366.926811  368.810730  45303600\n",
       "...                ...         ...         ...         ...       ...\n",
       "2022-12-06  397.594260  398.161631  389.849824  392.029785  77972200\n",
       "2022-12-07  391.143858  393.831529  390.178291  391.362854  65927900\n",
       "2022-12-08  393.333824  395.543648  391.472347  394.428772  60737900\n",
       "2022-12-09  393.134716  395.802458  391.352889  391.482300  81367500\n",
       "2022-12-12  392.308501  397.126404  391.611719  397.126404  75405800\n",
       "\n",
       "[487 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.iloc[:-17 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35327628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
