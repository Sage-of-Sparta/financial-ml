{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "247d14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler # for normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline # pipeline making\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics # for the check the error and accuracy of the model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "## for Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b946aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Ref: https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80a8417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/20days_supervised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09238f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spy_oc_ret</th>\n",
       "      <th>spy_pco_ret</th>\n",
       "      <th>spy_volume</th>\n",
       "      <th>spy_volatility_atr</th>\n",
       "      <th>spy_trend_ichimoku_conv</th>\n",
       "      <th>spy_trend_ichimoku_base</th>\n",
       "      <th>spy_trend_ichimoku_a</th>\n",
       "      <th>spy_trend_ichimoku_b</th>\n",
       "      <th>spy_trend_cci</th>\n",
       "      <th>spy_momentum_rsi</th>\n",
       "      <th>...</th>\n",
       "      <th>month7_1</th>\n",
       "      <th>month8_1</th>\n",
       "      <th>month9_1</th>\n",
       "      <th>month10_1</th>\n",
       "      <th>month11_1</th>\n",
       "      <th>month12_1</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.165508</td>\n",
       "      <td>-0.245295</td>\n",
       "      <td>825307.0</td>\n",
       "      <td>1.669605</td>\n",
       "      <td>210.485</td>\n",
       "      <td>205.050</td>\n",
       "      <td>207.7675</td>\n",
       "      <td>205.415</td>\n",
       "      <td>61.959043</td>\n",
       "      <td>60.817866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.080798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.080798</td>\n",
       "      <td>-0.341038</td>\n",
       "      <td>823814.0</td>\n",
       "      <td>1.708645</td>\n",
       "      <td>210.485</td>\n",
       "      <td>205.050</td>\n",
       "      <td>207.7675</td>\n",
       "      <td>205.415</td>\n",
       "      <td>28.466826</td>\n",
       "      <td>56.898993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.075966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.075966</td>\n",
       "      <td>0.185511</td>\n",
       "      <td>603513.0</td>\n",
       "      <td>1.632780</td>\n",
       "      <td>210.650</td>\n",
       "      <td>205.050</td>\n",
       "      <td>207.8500</td>\n",
       "      <td>205.415</td>\n",
       "      <td>38.230788</td>\n",
       "      <td>57.658306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.916818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.916818</td>\n",
       "      <td>-0.494156</td>\n",
       "      <td>1179812.0</td>\n",
       "      <td>1.805502</td>\n",
       "      <td>209.670</td>\n",
       "      <td>205.050</td>\n",
       "      <td>207.3600</td>\n",
       "      <td>205.050</td>\n",
       "      <td>-52.094807</td>\n",
       "      <td>46.343006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.298450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298450</td>\n",
       "      <td>0.115663</td>\n",
       "      <td>695836.0</td>\n",
       "      <td>1.753952</td>\n",
       "      <td>209.670</td>\n",
       "      <td>205.050</td>\n",
       "      <td>207.3600</td>\n",
       "      <td>205.050</td>\n",
       "      <td>-59.867129</td>\n",
       "      <td>49.447146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.836921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>-0.347358</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>530326.0</td>\n",
       "      <td>6.613262</td>\n",
       "      <td>401.330</td>\n",
       "      <td>389.395</td>\n",
       "      <td>395.3625</td>\n",
       "      <td>379.055</td>\n",
       "      <td>122.555934</td>\n",
       "      <td>63.392394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1.160998</td>\n",
       "      <td>-1.261721</td>\n",
       "      <td>513953.0</td>\n",
       "      <td>6.523936</td>\n",
       "      <td>401.330</td>\n",
       "      <td>389.395</td>\n",
       "      <td>395.3625</td>\n",
       "      <td>379.055</td>\n",
       "      <td>109.592125</td>\n",
       "      <td>62.875939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.079342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>-1.079342</td>\n",
       "      <td>-0.727434</td>\n",
       "      <td>501248.0</td>\n",
       "      <td>6.745542</td>\n",
       "      <td>401.650</td>\n",
       "      <td>389.395</td>\n",
       "      <td>395.5225</td>\n",
       "      <td>379.055</td>\n",
       "      <td>61.395549</td>\n",
       "      <td>55.317131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.399529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>-1.399529</td>\n",
       "      <td>-0.042544</td>\n",
       "      <td>562006.0</td>\n",
       "      <td>6.905988</td>\n",
       "      <td>400.820</td>\n",
       "      <td>389.395</td>\n",
       "      <td>395.1075</td>\n",
       "      <td>379.055</td>\n",
       "      <td>-17.096376</td>\n",
       "      <td>50.202757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>0.066175</td>\n",
       "      <td>-0.236142</td>\n",
       "      <td>427331.0</td>\n",
       "      <td>6.582389</td>\n",
       "      <td>400.820</td>\n",
       "      <td>389.395</td>\n",
       "      <td>395.1075</td>\n",
       "      <td>379.055</td>\n",
       "      <td>-53.987909</td>\n",
       "      <td>49.627984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1943 rows × 2684 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spy_oc_ret  spy_pco_ret  spy_volume  spy_volatility_atr  \\\n",
       "0      -0.165508    -0.245295    825307.0            1.669605   \n",
       "1      -0.080798    -0.341038    823814.0            1.708645   \n",
       "2      -0.075966     0.185511    603513.0            1.632780   \n",
       "3      -0.916818    -0.494156   1179812.0            1.805502   \n",
       "4       0.298450     0.115663    695836.0            1.753952   \n",
       "...          ...          ...         ...                 ...   \n",
       "1938   -0.347358     0.274725    530326.0            6.613262   \n",
       "1939    1.160998    -1.261721    513953.0            6.523936   \n",
       "1940   -1.079342    -0.727434    501248.0            6.745542   \n",
       "1941   -1.399529    -0.042544    562006.0            6.905988   \n",
       "1942    0.066175    -0.236142    427331.0            6.582389   \n",
       "\n",
       "      spy_trend_ichimoku_conv  spy_trend_ichimoku_base  spy_trend_ichimoku_a  \\\n",
       "0                     210.485                  205.050              207.7675   \n",
       "1                     210.485                  205.050              207.7675   \n",
       "2                     210.650                  205.050              207.8500   \n",
       "3                     209.670                  205.050              207.3600   \n",
       "4                     209.670                  205.050              207.3600   \n",
       "...                       ...                      ...                   ...   \n",
       "1938                  401.330                  389.395              395.3625   \n",
       "1939                  401.330                  389.395              395.3625   \n",
       "1940                  401.650                  389.395              395.5225   \n",
       "1941                  400.820                  389.395              395.1075   \n",
       "1942                  400.820                  389.395              395.1075   \n",
       "\n",
       "      spy_trend_ichimoku_b  spy_trend_cci  spy_momentum_rsi  ...  month7_1  \\\n",
       "0                  205.415      61.959043         60.817866  ...       0.0   \n",
       "1                  205.415      28.466826         56.898993  ...       0.0   \n",
       "2                  205.415      38.230788         57.658306  ...       0.0   \n",
       "3                  205.050     -52.094807         46.343006  ...       0.0   \n",
       "4                  205.050     -59.867129         49.447146  ...       0.0   \n",
       "...                    ...            ...               ...  ...       ...   \n",
       "1938               379.055     122.555934         63.392394  ...       0.0   \n",
       "1939               379.055     109.592125         62.875939  ...       0.0   \n",
       "1940               379.055      61.395549         55.317131  ...       0.0   \n",
       "1941               379.055     -17.096376         50.202757  ...       0.0   \n",
       "1942               379.055     -53.987909         49.627984  ...       0.0   \n",
       "\n",
       "      month8_1  month9_1  month10_1  month11_1  month12_1  target_1  target_2  \\\n",
       "0          0.0       0.0        0.0        0.0        0.0       0.0       1.0   \n",
       "1          0.0       0.0        0.0        0.0        0.0       1.0       0.0   \n",
       "2          0.0       0.0        0.0        0.0        0.0       0.0       1.0   \n",
       "3          0.0       0.0        0.0        0.0        0.0       0.0       0.0   \n",
       "4          0.0       0.0        0.0        0.0        0.0       0.0       1.0   \n",
       "...        ...       ...        ...        ...        ...       ...       ...   \n",
       "1938       0.0       0.0        0.0        1.0        0.0       0.0       1.0   \n",
       "1939       0.0       0.0        0.0        1.0        0.0       0.0       1.0   \n",
       "1940       0.0       0.0        0.0        1.0        0.0       0.0       1.0   \n",
       "1941       0.0       0.0        0.0        1.0        0.0       0.0       1.0   \n",
       "1942       0.0       0.0        0.0        1.0        0.0       1.0       0.0   \n",
       "\n",
       "      target_3    target  \n",
       "0          0.0 -0.080798  \n",
       "1          0.0 -0.075966  \n",
       "2          0.0 -0.916818  \n",
       "3          1.0  0.298450  \n",
       "4          0.0 -0.836921  \n",
       "...        ...       ...  \n",
       "1938       0.0  1.160998  \n",
       "1939       0.0 -1.079342  \n",
       "1940       0.0 -1.399529  \n",
       "1941       0.0  0.066175  \n",
       "1942       0.0       NaN  \n",
       "\n",
       "[1943 rows x 2684 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['target'] = df['target_1']+df['target_2']*2+df['target_3']*3\n",
    "#df['target'] = np.where(df['target']==3.0,0.0,df['target'])\n",
    "\n",
    "df['target'] = df['spy_oc_ret'].shift(-1)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c51493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c209a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 1, 2680) (1360, 1) (583, 1, 2680) (583, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = df[df.columns[~df.columns.isin(\n",
    "    ['datecol', 'target','trade_date','target_1','target_2','target_3'])]]\n",
    "#y = df[['target_1','target_2','target_3']]\n",
    "y = df['target']\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "#\n",
    "\n",
    "n_train_time = round(df.shape[0] * 0.7)\n",
    "train = df.iloc[:n_train_time, :]\n",
    "test = df.iloc[n_train_time:, :]\n",
    "\n",
    "train_X = train[train.columns[~train.columns.isin(['datecol', 'target','trade_date','target_1','target_2','target_3'])]]\n",
    "#train_y = train[['target_1','target_2','target_3']]\n",
    "train_y = train[['target']]\n",
    "\n",
    "\n",
    "test_X = test[test.columns[~test.columns.isin(['datecol', 'target','trade_date','target_1','target_2','target_3'])]]\n",
    "#test_y = test[['target_1','target_2','target_3']]\n",
    "test_y = test[['target']]\n",
    "\n",
    "train_X = train_X.values\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "\n",
    "train_y = train_y.values\n",
    "test_X = test_X.values\n",
    "test_X_scaled = scaler.fit_transform(test_X)\n",
    "\n",
    "test_y = test_y.values\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "train_X_scaled = train_X_scaled.reshape((train_X_scaled.shape[0], 1, train_X_scaled.shape[1]))\n",
    "\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "test_X_scaled = test_X_scaled.reshape((test_X_scaled.shape[0], 1, test_X_scaled.shape[1]))\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed4013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7507b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "7/7 - 2s - loss: -2.4634e-01 - val_loss: -8.9595e-01 - 2s/epoch - 234ms/step\n",
      "Epoch 2/300\n",
      "7/7 - 0s - loss: -6.8479e-01 - val_loss: -1.1174e+00 - 107ms/epoch - 15ms/step\n",
      "Epoch 3/300\n",
      "7/7 - 0s - loss: -7.9606e-01 - val_loss: -1.2582e+00 - 100ms/epoch - 14ms/step\n",
      "Epoch 4/300\n",
      "7/7 - 0s - loss: -8.7084e-01 - val_loss: -1.3534e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 5/300\n",
      "7/7 - 0s - loss: -9.2687e-01 - val_loss: -1.4309e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 6/300\n",
      "7/7 - 0s - loss: -1.0018e+00 - val_loss: -1.5179e+00 - 99ms/epoch - 14ms/step\n",
      "Epoch 7/300\n",
      "7/7 - 0s - loss: -1.0413e+00 - val_loss: -1.5829e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 8/300\n",
      "7/7 - 0s - loss: -1.1180e+00 - val_loss: -1.6465e+00 - 101ms/epoch - 14ms/step\n",
      "Epoch 9/300\n",
      "7/7 - 0s - loss: -1.1338e+00 - val_loss: -1.7216e+00 - 102ms/epoch - 15ms/step\n",
      "Epoch 10/300\n",
      "7/7 - 0s - loss: -1.2213e+00 - val_loss: -1.8112e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 11/300\n",
      "7/7 - 0s - loss: -1.1978e+00 - val_loss: -1.8792e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 12/300\n",
      "7/7 - 0s - loss: -1.3422e+00 - val_loss: -1.9445e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 13/300\n",
      "7/7 - 0s - loss: -1.3548e+00 - val_loss: -2.0125e+00 - 101ms/epoch - 14ms/step\n",
      "Epoch 14/300\n",
      "7/7 - 0s - loss: -1.3595e+00 - val_loss: -2.1010e+00 - 99ms/epoch - 14ms/step\n",
      "Epoch 15/300\n",
      "7/7 - 0s - loss: -1.4383e+00 - val_loss: -2.1699e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 16/300\n",
      "7/7 - 0s - loss: -1.5110e+00 - val_loss: -2.2372e+00 - 95ms/epoch - 14ms/step\n",
      "Epoch 17/300\n",
      "7/7 - 0s - loss: -1.5423e+00 - val_loss: -2.3295e+00 - 100ms/epoch - 14ms/step\n",
      "Epoch 18/300\n",
      "7/7 - 0s - loss: -1.6077e+00 - val_loss: -2.3984e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 19/300\n",
      "7/7 - 0s - loss: -1.6345e+00 - val_loss: -2.4653e+00 - 107ms/epoch - 15ms/step\n",
      "Epoch 20/300\n",
      "7/7 - 0s - loss: -1.6934e+00 - val_loss: -2.5325e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 21/300\n",
      "7/7 - 0s - loss: -1.7542e+00 - val_loss: -2.5991e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 22/300\n",
      "7/7 - 0s - loss: -1.8042e+00 - val_loss: -2.6662e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 23/300\n",
      "7/7 - 0s - loss: -1.8559e+00 - val_loss: -2.7325e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 24/300\n",
      "7/7 - 0s - loss: -1.8467e+00 - val_loss: -2.7983e+00 - 100ms/epoch - 14ms/step\n",
      "Epoch 25/300\n",
      "7/7 - 0s - loss: -1.8755e+00 - val_loss: -2.8647e+00 - 95ms/epoch - 14ms/step\n",
      "Epoch 26/300\n",
      "7/7 - 0s - loss: -1.9764e+00 - val_loss: -2.9317e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 27/300\n",
      "7/7 - 0s - loss: -2.0408e+00 - val_loss: -2.9990e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 28/300\n",
      "7/7 - 0s - loss: -2.0519e+00 - val_loss: -3.0661e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 29/300\n",
      "7/7 - 0s - loss: -2.1088e+00 - val_loss: -3.1484e+00 - 106ms/epoch - 15ms/step\n",
      "Epoch 30/300\n",
      "7/7 - 0s - loss: -2.1401e+00 - val_loss: -3.2209e+00 - 104ms/epoch - 15ms/step\n",
      "Epoch 31/300\n",
      "7/7 - 0s - loss: -2.2074e+00 - val_loss: -3.2891e+00 - 105ms/epoch - 15ms/step\n",
      "Epoch 32/300\n",
      "7/7 - 0s - loss: -2.2491e+00 - val_loss: -3.3565e+00 - 118ms/epoch - 17ms/step\n",
      "Epoch 33/300\n",
      "7/7 - 0s - loss: -2.2832e+00 - val_loss: -3.4240e+00 - 127ms/epoch - 18ms/step\n",
      "Epoch 34/300\n",
      "7/7 - 0s - loss: -2.3103e+00 - val_loss: -3.4906e+00 - 119ms/epoch - 17ms/step\n",
      "Epoch 35/300\n",
      "7/7 - 0s - loss: -2.3588e+00 - val_loss: -3.5566e+00 - 99ms/epoch - 14ms/step\n",
      "Epoch 36/300\n",
      "7/7 - 0s - loss: -2.3870e+00 - val_loss: -3.6227e+00 - 100ms/epoch - 14ms/step\n",
      "Epoch 37/300\n",
      "7/7 - 0s - loss: -2.4626e+00 - val_loss: -3.6890e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 38/300\n",
      "7/7 - 0s - loss: -2.5956e+00 - val_loss: -3.7560e+00 - 103ms/epoch - 15ms/step\n",
      "Epoch 39/300\n",
      "7/7 - 0s - loss: -2.6740e+00 - val_loss: -3.8399e+00 - 109ms/epoch - 16ms/step\n",
      "Epoch 40/300\n",
      "7/7 - 0s - loss: -2.7490e+00 - val_loss: -3.9238e+00 - 135ms/epoch - 19ms/step\n",
      "Epoch 41/300\n",
      "7/7 - 0s - loss: -2.7531e+00 - val_loss: -3.9964e+00 - 107ms/epoch - 15ms/step\n",
      "Epoch 42/300\n",
      "7/7 - 0s - loss: -2.7471e+00 - val_loss: -4.0681e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 43/300\n",
      "7/7 - 0s - loss: -2.7459e+00 - val_loss: -4.1387e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 44/300\n",
      "7/7 - 0s - loss: -2.8348e+00 - val_loss: -4.2088e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 45/300\n",
      "7/7 - 0s - loss: -2.8318e+00 - val_loss: -4.2780e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 46/300\n",
      "7/7 - 0s - loss: -2.8982e+00 - val_loss: -4.3467e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 47/300\n",
      "7/7 - 0s - loss: -2.9072e+00 - val_loss: -4.4151e+00 - 101ms/epoch - 14ms/step\n",
      "Epoch 48/300\n",
      "7/7 - 0s - loss: -2.9867e+00 - val_loss: -4.4825e+00 - 103ms/epoch - 15ms/step\n",
      "Epoch 49/300\n",
      "7/7 - 0s - loss: -3.0321e+00 - val_loss: -4.5504e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 50/300\n",
      "7/7 - 0s - loss: -3.0532e+00 - val_loss: -4.6178e+00 - 119ms/epoch - 17ms/step\n",
      "Epoch 51/300\n",
      "7/7 - 0s - loss: -3.1924e+00 - val_loss: -4.6855e+00 - 118ms/epoch - 17ms/step\n",
      "Epoch 52/300\n",
      "7/7 - 0s - loss: -3.2527e+00 - val_loss: -4.7537e+00 - 116ms/epoch - 17ms/step\n",
      "Epoch 53/300\n",
      "7/7 - 0s - loss: -3.3707e+00 - val_loss: -4.8231e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 54/300\n",
      "7/7 - 0s - loss: -3.3156e+00 - val_loss: -4.8920e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 55/300\n",
      "7/7 - 0s - loss: -3.3804e+00 - val_loss: -4.9602e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 56/300\n",
      "7/7 - 0s - loss: -3.4045e+00 - val_loss: -5.0286e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 57/300\n",
      "7/7 - 0s - loss: -3.5249e+00 - val_loss: -5.0969e+00 - 105ms/epoch - 15ms/step\n",
      "Epoch 58/300\n",
      "7/7 - 0s - loss: -3.4415e+00 - val_loss: -5.1651e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 59/300\n",
      "7/7 - 0s - loss: -3.5139e+00 - val_loss: -5.2323e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 60/300\n",
      "7/7 - 0s - loss: -3.5150e+00 - val_loss: -5.2993e+00 - 123ms/epoch - 18ms/step\n",
      "Epoch 61/300\n",
      "7/7 - 0s - loss: -3.6282e+00 - val_loss: -5.3664e+00 - 109ms/epoch - 16ms/step\n",
      "Epoch 62/300\n",
      "7/7 - 0s - loss: -3.7202e+00 - val_loss: -5.4338e+00 - 103ms/epoch - 15ms/step\n",
      "Epoch 63/300\n",
      "7/7 - 0s - loss: -3.6502e+00 - val_loss: -5.5004e+00 - 95ms/epoch - 14ms/step\n",
      "Epoch 64/300\n",
      "7/7 - 0s - loss: -3.7383e+00 - val_loss: -5.5668e+00 - 93ms/epoch - 13ms/step\n",
      "Epoch 65/300\n",
      "7/7 - 0s - loss: -3.8133e+00 - val_loss: -5.6333e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 66/300\n",
      "7/7 - 0s - loss: -3.8976e+00 - val_loss: -5.7004e+00 - 111ms/epoch - 16ms/step\n",
      "Epoch 67/300\n",
      "7/7 - 0s - loss: -3.9873e+00 - val_loss: -5.7679e+00 - 111ms/epoch - 16ms/step\n",
      "Epoch 68/300\n",
      "7/7 - 0s - loss: -3.9956e+00 - val_loss: -5.8361e+00 - 115ms/epoch - 16ms/step\n",
      "Epoch 69/300\n",
      "7/7 - 0s - loss: -3.9356e+00 - val_loss: -5.9031e+00 - 113ms/epoch - 16ms/step\n",
      "Epoch 70/300\n",
      "7/7 - 0s - loss: -3.9935e+00 - val_loss: -5.9695e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 71/300\n",
      "7/7 - 0s - loss: -4.0776e+00 - val_loss: -6.0363e+00 - 92ms/epoch - 13ms/step\n",
      "Epoch 72/300\n",
      "7/7 - 0s - loss: -4.1780e+00 - val_loss: -6.1034e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 73/300\n",
      "7/7 - 0s - loss: -4.1605e+00 - val_loss: -6.1700e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 74/300\n",
      "7/7 - 0s - loss: -4.2874e+00 - val_loss: -6.2370e+00 - 93ms/epoch - 13ms/step\n",
      "Epoch 75/300\n",
      "7/7 - 0s - loss: -4.2087e+00 - val_loss: -6.3033e+00 - 95ms/epoch - 14ms/step\n",
      "Epoch 76/300\n",
      "7/7 - 0s - loss: -4.2865e+00 - val_loss: -6.3708e+00 - 113ms/epoch - 16ms/step\n",
      "Epoch 77/300\n",
      "7/7 - 0s - loss: -4.4233e+00 - val_loss: -6.4374e+00 - 133ms/epoch - 19ms/step\n",
      "Epoch 78/300\n",
      "7/7 - 0s - loss: -4.4834e+00 - val_loss: -6.5049e+00 - 104ms/epoch - 15ms/step\n",
      "Epoch 79/300\n",
      "7/7 - 0s - loss: -4.4536e+00 - val_loss: -6.5579e+00 - 100ms/epoch - 14ms/step\n",
      "Epoch 80/300\n",
      "7/7 - 0s - loss: -4.5734e+00 - val_loss: -6.6325e+00 - 98ms/epoch - 14ms/step\n",
      "Epoch 81/300\n",
      "7/7 - 0s - loss: -4.5544e+00 - val_loss: -6.7063e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 82/300\n",
      "7/7 - 0s - loss: -4.7706e+00 - val_loss: -6.7731e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 83/300\n",
      "7/7 - 0s - loss: -4.5924e+00 - val_loss: -6.8413e+00 - 93ms/epoch - 13ms/step\n",
      "Epoch 84/300\n",
      "7/7 - 0s - loss: -4.6634e+00 - val_loss: -6.9052e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 85/300\n",
      "7/7 - 0s - loss: -4.8697e+00 - val_loss: -6.9708e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 86/300\n",
      "7/7 - 0s - loss: -4.8941e+00 - val_loss: -6.9599e+00 - 102ms/epoch - 15ms/step\n",
      "Epoch 87/300\n",
      "7/7 - 0s - loss: -4.7628e+00 - val_loss: -7.1103e+00 - 102ms/epoch - 15ms/step\n",
      "Epoch 88/300\n",
      "7/7 - 0s - loss: -4.9638e+00 - val_loss: -7.1765e+00 - 102ms/epoch - 15ms/step\n",
      "Epoch 89/300\n",
      "7/7 - 0s - loss: -4.8466e+00 - val_loss: -7.2432e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 90/300\n",
      "7/7 - 0s - loss: -4.9737e+00 - val_loss: -7.3087e+00 - 95ms/epoch - 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/300\n",
      "7/7 - 0s - loss: -5.0286e+00 - val_loss: -7.3728e+00 - 92ms/epoch - 13ms/step\n",
      "Epoch 92/300\n",
      "7/7 - 0s - loss: -5.0347e+00 - val_loss: -7.4416e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 93/300\n",
      "7/7 - 0s - loss: -5.0315e+00 - val_loss: -7.5070e+00 - 93ms/epoch - 13ms/step\n",
      "Epoch 94/300\n",
      "7/7 - 0s - loss: -5.1893e+00 - val_loss: -7.5719e+00 - 93ms/epoch - 13ms/step\n",
      "Epoch 95/300\n",
      "7/7 - 0s - loss: -5.3329e+00 - val_loss: -7.6392e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 96/300\n",
      "7/7 - 0s - loss: -5.2390e+00 - val_loss: -7.7127e+00 - 100ms/epoch - 14ms/step\n",
      "Epoch 97/300\n",
      "7/7 - 0s - loss: -5.5567e+00 - val_loss: -7.7928e+00 - 105ms/epoch - 15ms/step\n",
      "Epoch 98/300\n",
      "7/7 - 0s - loss: -5.4410e+00 - val_loss: -7.8540e+00 - 99ms/epoch - 14ms/step\n",
      "Epoch 99/300\n",
      "7/7 - 0s - loss: -5.2378e+00 - val_loss: -7.9365e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 100/300\n",
      "7/7 - 0s - loss: -5.4278e+00 - val_loss: -8.0131e+00 - 100ms/epoch - 14ms/step\n",
      "Epoch 101/300\n",
      "7/7 - 0s - loss: -5.3260e+00 - val_loss: -8.0838e+00 - 104ms/epoch - 15ms/step\n",
      "Epoch 102/300\n",
      "7/7 - 0s - loss: -5.5843e+00 - val_loss: -8.1486e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 103/300\n",
      "7/7 - 0s - loss: -5.5267e+00 - val_loss: -8.2250e+00 - 95ms/epoch - 14ms/step\n",
      "Epoch 104/300\n",
      "7/7 - 0s - loss: -5.6168e+00 - val_loss: -8.2971e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 105/300\n",
      "7/7 - 0s - loss: -5.8041e+00 - val_loss: -8.3757e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 106/300\n",
      "7/7 - 0s - loss: -5.7913e+00 - val_loss: -8.4407e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 107/300\n",
      "7/7 - 0s - loss: -5.8792e+00 - val_loss: -8.5203e+00 - 121ms/epoch - 17ms/step\n",
      "Epoch 108/300\n",
      "7/7 - 0s - loss: -5.8755e+00 - val_loss: -8.5719e+00 - 116ms/epoch - 17ms/step\n",
      "Epoch 109/300\n",
      "7/7 - 0s - loss: -6.0264e+00 - val_loss: -8.6648e+00 - 104ms/epoch - 15ms/step\n",
      "Epoch 110/300\n",
      "7/7 - 0s - loss: -5.8964e+00 - val_loss: -8.7262e+00 - 102ms/epoch - 15ms/step\n",
      "Epoch 111/300\n",
      "7/7 - 0s - loss: -6.0402e+00 - val_loss: -8.8061e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 112/300\n",
      "7/7 - 0s - loss: -6.1724e+00 - val_loss: -8.8655e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 113/300\n",
      "7/7 - 0s - loss: -6.0849e+00 - val_loss: -8.9510e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 114/300\n",
      "7/7 - 0s - loss: -6.2641e+00 - val_loss: -9.0268e+00 - 93ms/epoch - 13ms/step\n",
      "Epoch 115/300\n",
      "7/7 - 0s - loss: -6.2289e+00 - val_loss: -9.0794e+00 - 94ms/epoch - 13ms/step\n",
      "Epoch 116/300\n",
      "7/7 - 0s - loss: -6.4448e+00 - val_loss: -9.1680e+00 - 107ms/epoch - 15ms/step\n",
      "Epoch 117/300\n",
      "7/7 - 0s - loss: -6.2968e+00 - val_loss: -9.2043e+00 - 107ms/epoch - 15ms/step\n",
      "Epoch 118/300\n",
      "7/7 - 0s - loss: -6.4172e+00 - val_loss: -9.3126e+00 - 109ms/epoch - 16ms/step\n",
      "Epoch 119/300\n",
      "7/7 - 0s - loss: -6.4821e+00 - val_loss: -9.3702e+00 - 110ms/epoch - 16ms/step\n",
      "Epoch 120/300\n",
      "7/7 - 0s - loss: -6.4746e+00 - val_loss: -9.4319e+00 - 105ms/epoch - 15ms/step\n",
      "Epoch 121/300\n",
      "7/7 - 0s - loss: -6.6117e+00 - val_loss: -9.5122e+00 - 102ms/epoch - 15ms/step\n",
      "Epoch 122/300\n",
      "7/7 - 0s - loss: -6.5702e+00 - val_loss: -9.5756e+00 - 99ms/epoch - 14ms/step\n",
      "Epoch 123/300\n",
      "7/7 - 0s - loss: -6.7172e+00 - val_loss: -9.6539e+00 - 99ms/epoch - 14ms/step\n",
      "Epoch 124/300\n",
      "7/7 - 0s - loss: -6.7144e+00 - val_loss: -9.7355e+00 - 96ms/epoch - 14ms/step\n",
      "Epoch 125/300\n",
      "7/7 - 0s - loss: -6.8517e+00 - val_loss: -9.7933e+00 - 93ms/epoch - 13ms/step\n",
      "Epoch 126/300\n",
      "7/7 - 0s - loss: -6.8074e+00 - val_loss: -9.8738e+00 - 109ms/epoch - 16ms/step\n",
      "Epoch 127/300\n",
      "7/7 - 0s - loss: -6.8768e+00 - val_loss: -9.9090e+00 - 97ms/epoch - 14ms/step\n",
      "Epoch 128/300\n",
      "7/7 - 0s - loss: -6.9045e+00 - val_loss: -9.9881e+00 - 103ms/epoch - 15ms/step\n",
      "Epoch 129/300\n",
      "7/7 - 0s - loss: -7.0595e+00 - val_loss: -1.0081e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 130/300\n",
      "7/7 - 0s - loss: -7.0044e+00 - val_loss: -1.0146e+01 - 107ms/epoch - 15ms/step\n",
      "Epoch 131/300\n",
      "7/7 - 0s - loss: -7.2450e+00 - val_loss: -1.0212e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 132/300\n",
      "7/7 - 0s - loss: -7.0858e+00 - val_loss: -1.0280e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 133/300\n",
      "7/7 - 0s - loss: -7.0091e+00 - val_loss: -1.0322e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 134/300\n",
      "7/7 - 0s - loss: -7.2084e+00 - val_loss: -1.0421e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 135/300\n",
      "7/7 - 0s - loss: -7.3372e+00 - val_loss: -1.0470e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 136/300\n",
      "7/7 - 0s - loss: -7.2396e+00 - val_loss: -1.0548e+01 - 107ms/epoch - 15ms/step\n",
      "Epoch 137/300\n",
      "7/7 - 0s - loss: -7.6289e+00 - val_loss: -1.0614e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 138/300\n",
      "7/7 - 0s - loss: -7.5102e+00 - val_loss: -1.0674e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 139/300\n",
      "7/7 - 0s - loss: -7.5061e+00 - val_loss: -1.0759e+01 - 112ms/epoch - 16ms/step\n",
      "Epoch 140/300\n",
      "7/7 - 0s - loss: -7.5911e+00 - val_loss: -1.0811e+01 - 104ms/epoch - 15ms/step\n",
      "Epoch 141/300\n",
      "7/7 - 0s - loss: -7.5930e+00 - val_loss: -1.0855e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 142/300\n",
      "7/7 - 0s - loss: -7.6226e+00 - val_loss: -1.0954e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 143/300\n",
      "7/7 - 0s - loss: -7.9323e+00 - val_loss: -1.1018e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 144/300\n",
      "7/7 - 0s - loss: -7.8018e+00 - val_loss: -1.1072e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 145/300\n",
      "7/7 - 0s - loss: -7.8355e+00 - val_loss: -1.1135e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 146/300\n",
      "7/7 - 0s - loss: -7.9322e+00 - val_loss: -1.1212e+01 - 105ms/epoch - 15ms/step\n",
      "Epoch 147/300\n",
      "7/7 - 0s - loss: -7.8060e+00 - val_loss: -1.1305e+01 - 104ms/epoch - 15ms/step\n",
      "Epoch 148/300\n",
      "7/7 - 0s - loss: -8.2510e+00 - val_loss: -1.1364e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 149/300\n",
      "7/7 - 0s - loss: -8.0293e+00 - val_loss: -1.1443e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 150/300\n",
      "7/7 - 0s - loss: -8.4394e+00 - val_loss: -1.1504e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 151/300\n",
      "7/7 - 0s - loss: -8.3569e+00 - val_loss: -1.1584e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 152/300\n",
      "7/7 - 0s - loss: -8.3265e+00 - val_loss: -1.1630e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 153/300\n",
      "7/7 - 0s - loss: -8.5649e+00 - val_loss: -1.1744e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 154/300\n",
      "7/7 - 0s - loss: -8.4090e+00 - val_loss: -1.1780e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 155/300\n",
      "7/7 - 0s - loss: -8.7110e+00 - val_loss: -1.1868e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 156/300\n",
      "7/7 - 0s - loss: -8.6233e+00 - val_loss: -1.1910e+01 - 109ms/epoch - 16ms/step\n",
      "Epoch 157/300\n",
      "7/7 - 0s - loss: -8.6282e+00 - val_loss: -1.1990e+01 - 111ms/epoch - 16ms/step\n",
      "Epoch 158/300\n",
      "7/7 - 0s - loss: -8.5918e+00 - val_loss: -1.2079e+01 - 110ms/epoch - 16ms/step\n",
      "Epoch 159/300\n",
      "7/7 - 0s - loss: -8.8766e+00 - val_loss: -1.2128e+01 - 110ms/epoch - 16ms/step\n",
      "Epoch 160/300\n",
      "7/7 - 0s - loss: -8.7959e+00 - val_loss: -1.2148e+01 - 103ms/epoch - 15ms/step\n",
      "Epoch 161/300\n",
      "7/7 - 0s - loss: -8.6502e+00 - val_loss: -1.2202e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 162/300\n",
      "7/7 - 0s - loss: -9.0901e+00 - val_loss: -1.2360e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 163/300\n",
      "7/7 - 0s - loss: -8.9262e+00 - val_loss: -1.2153e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 164/300\n",
      "7/7 - 0s - loss: -8.9002e+00 - val_loss: -1.2244e+01 - 91ms/epoch - 13ms/step\n",
      "Epoch 165/300\n",
      "7/7 - 0s - loss: -9.2995e+00 - val_loss: -1.2314e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 166/300\n",
      "7/7 - 0s - loss: -9.0110e+00 - val_loss: -1.2373e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 167/300\n",
      "7/7 - 0s - loss: -9.2503e+00 - val_loss: -1.2422e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 168/300\n",
      "7/7 - 0s - loss: -9.1973e+00 - val_loss: -1.2523e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 169/300\n",
      "7/7 - 0s - loss: -9.2912e+00 - val_loss: -1.2520e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 170/300\n",
      "7/7 - 0s - loss: -9.2411e+00 - val_loss: -1.2668e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 171/300\n",
      "7/7 - 0s - loss: -9.4410e+00 - val_loss: -1.2735e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 172/300\n",
      "7/7 - 0s - loss: -9.6208e+00 - val_loss: -1.2751e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 173/300\n",
      "7/7 - 0s - loss: -9.7388e+00 - val_loss: -1.2859e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 174/300\n",
      "7/7 - 0s - loss: -9.5711e+00 - val_loss: -1.2889e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 175/300\n",
      "7/7 - 0s - loss: -9.5972e+00 - val_loss: -1.3012e+01 - 92ms/epoch - 13ms/step\n",
      "Epoch 176/300\n",
      "7/7 - 0s - loss: -9.7160e+00 - val_loss: -1.3061e+01 - 104ms/epoch - 15ms/step\n",
      "Epoch 177/300\n",
      "7/7 - 0s - loss: -9.8614e+00 - val_loss: -1.3112e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 178/300\n",
      "7/7 - 0s - loss: -1.0086e+01 - val_loss: -1.3182e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 179/300\n",
      "7/7 - 0s - loss: -1.0151e+01 - val_loss: -1.3267e+01 - 108ms/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "7/7 - 0s - loss: -9.8689e+00 - val_loss: -1.3302e+01 - 107ms/epoch - 15ms/step\n",
      "Epoch 181/300\n",
      "7/7 - 0s - loss: -1.0024e+01 - val_loss: -1.3384e+01 - 104ms/epoch - 15ms/step\n",
      "Epoch 182/300\n",
      "7/7 - 0s - loss: -1.0350e+01 - val_loss: -1.3468e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 183/300\n",
      "7/7 - 0s - loss: -1.0547e+01 - val_loss: -1.3523e+01 - 99ms/epoch - 14ms/step\n",
      "Epoch 184/300\n",
      "7/7 - 0s - loss: -1.0420e+01 - val_loss: -1.3598e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 185/300\n",
      "7/7 - 0s - loss: -1.0598e+01 - val_loss: -1.3661e+01 - 106ms/epoch - 15ms/step\n",
      "Epoch 186/300\n",
      "7/7 - 0s - loss: -1.0710e+01 - val_loss: -1.3781e+01 - 115ms/epoch - 16ms/step\n",
      "Epoch 187/300\n",
      "7/7 - 0s - loss: -1.0659e+01 - val_loss: -1.3773e+01 - 104ms/epoch - 15ms/step\n",
      "Epoch 188/300\n",
      "7/7 - 0s - loss: -1.0946e+01 - val_loss: -1.3912e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 189/300\n",
      "7/7 - 0s - loss: -1.0863e+01 - val_loss: -1.3923e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 190/300\n",
      "7/7 - 0s - loss: -1.0759e+01 - val_loss: -1.4039e+01 - 92ms/epoch - 13ms/step\n",
      "Epoch 191/300\n",
      "7/7 - 0s - loss: -1.0902e+01 - val_loss: -1.4066e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 192/300\n",
      "7/7 - 0s - loss: -1.1109e+01 - val_loss: -1.4169e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 193/300\n",
      "7/7 - 0s - loss: -1.1171e+01 - val_loss: -1.4271e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 194/300\n",
      "7/7 - 0s - loss: -1.1036e+01 - val_loss: -1.4315e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 195/300\n",
      "7/7 - 0s - loss: -1.1136e+01 - val_loss: -1.4381e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 196/300\n",
      "7/7 - 0s - loss: -1.1128e+01 - val_loss: -1.4488e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 197/300\n",
      "7/7 - 0s - loss: -1.1587e+01 - val_loss: -1.4459e+01 - 99ms/epoch - 14ms/step\n",
      "Epoch 198/300\n",
      "7/7 - 0s - loss: -1.1290e+01 - val_loss: -1.4600e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 199/300\n",
      "7/7 - 0s - loss: -1.1962e+01 - val_loss: -1.4672e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 200/300\n",
      "7/7 - 0s - loss: -1.1706e+01 - val_loss: -1.4768e+01 - 103ms/epoch - 15ms/step\n",
      "Epoch 201/300\n",
      "7/7 - 0s - loss: -1.1648e+01 - val_loss: -1.4823e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 202/300\n",
      "7/7 - 0s - loss: -1.2004e+01 - val_loss: -1.4873e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 203/300\n",
      "7/7 - 0s - loss: -1.1778e+01 - val_loss: -1.4884e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 204/300\n",
      "7/7 - 0s - loss: -1.2150e+01 - val_loss: -1.5056e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 205/300\n",
      "7/7 - 0s - loss: -1.1891e+01 - val_loss: -1.5043e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 206/300\n",
      "7/7 - 0s - loss: -1.1996e+01 - val_loss: -1.5167e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 207/300\n",
      "7/7 - 0s - loss: -1.2400e+01 - val_loss: -1.5238e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 208/300\n",
      "7/7 - 0s - loss: -1.2780e+01 - val_loss: -1.5176e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 209/300\n",
      "7/7 - 0s - loss: -1.2371e+01 - val_loss: -1.5356e+01 - 107ms/epoch - 15ms/step\n",
      "Epoch 210/300\n",
      "7/7 - 0s - loss: -1.2599e+01 - val_loss: -1.5454e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 211/300\n",
      "7/7 - 0s - loss: -1.2455e+01 - val_loss: -1.5463e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 212/300\n",
      "7/7 - 0s - loss: -1.2706e+01 - val_loss: -1.5549e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 213/300\n",
      "7/7 - 0s - loss: -1.2882e+01 - val_loss: -1.5631e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 214/300\n",
      "7/7 - 0s - loss: -1.2788e+01 - val_loss: -1.5726e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 215/300\n",
      "7/7 - 0s - loss: -1.3112e+01 - val_loss: -1.5748e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 216/300\n",
      "7/7 - 0s - loss: -1.3018e+01 - val_loss: -1.5825e+01 - 109ms/epoch - 16ms/step\n",
      "Epoch 217/300\n",
      "7/7 - 0s - loss: -1.2952e+01 - val_loss: -1.5943e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 218/300\n",
      "7/7 - 0s - loss: -1.2911e+01 - val_loss: -1.5993e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 219/300\n",
      "7/7 - 0s - loss: -1.3304e+01 - val_loss: -1.6008e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 220/300\n",
      "7/7 - 0s - loss: -1.3217e+01 - val_loss: -1.6048e+01 - 99ms/epoch - 14ms/step\n",
      "Epoch 221/300\n",
      "7/7 - 0s - loss: -1.3508e+01 - val_loss: -1.5889e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 222/300\n",
      "7/7 - 0s - loss: -1.2912e+01 - val_loss: -1.5910e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 223/300\n",
      "7/7 - 0s - loss: -1.3506e+01 - val_loss: -1.5978e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 224/300\n",
      "7/7 - 0s - loss: -1.3603e+01 - val_loss: -1.6040e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 225/300\n",
      "7/7 - 0s - loss: -1.3612e+01 - val_loss: -1.6090e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 226/300\n",
      "7/7 - 0s - loss: -1.3656e+01 - val_loss: -1.6242e+01 - 121ms/epoch - 17ms/step\n",
      "Epoch 227/300\n",
      "7/7 - 0s - loss: -1.3563e+01 - val_loss: -1.6174e+01 - 109ms/epoch - 16ms/step\n",
      "Epoch 228/300\n",
      "7/7 - 0s - loss: -1.3919e+01 - val_loss: -1.6339e+01 - 110ms/epoch - 16ms/step\n",
      "Epoch 229/300\n",
      "7/7 - 0s - loss: -1.3790e+01 - val_loss: -1.6396e+01 - 104ms/epoch - 15ms/step\n",
      "Epoch 230/300\n",
      "7/7 - 0s - loss: -1.4000e+01 - val_loss: -1.6497e+01 - 105ms/epoch - 15ms/step\n",
      "Epoch 231/300\n",
      "7/7 - 0s - loss: -1.4146e+01 - val_loss: -1.6507e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 232/300\n",
      "7/7 - 0s - loss: -1.3844e+01 - val_loss: -1.6574e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 233/300\n",
      "7/7 - 0s - loss: -1.4352e+01 - val_loss: -1.6678e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 234/300\n",
      "7/7 - 0s - loss: -1.4474e+01 - val_loss: -1.6654e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 235/300\n",
      "7/7 - 0s - loss: -1.4363e+01 - val_loss: -1.6801e+01 - 112ms/epoch - 16ms/step\n",
      "Epoch 236/300\n",
      "7/7 - 0s - loss: -1.4730e+01 - val_loss: -1.6937e+01 - 106ms/epoch - 15ms/step\n",
      "Epoch 237/300\n",
      "7/7 - 0s - loss: -1.4760e+01 - val_loss: -1.6956e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 238/300\n",
      "7/7 - 0s - loss: -1.4731e+01 - val_loss: -1.7074e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 239/300\n",
      "7/7 - 0s - loss: -1.4959e+01 - val_loss: -1.7120e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 240/300\n",
      "7/7 - 0s - loss: -1.4728e+01 - val_loss: -1.7182e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 241/300\n",
      "7/7 - 0s - loss: -1.4922e+01 - val_loss: -1.7277e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 242/300\n",
      "7/7 - 0s - loss: -1.4990e+01 - val_loss: -1.7286e+01 - 91ms/epoch - 13ms/step\n",
      "Epoch 243/300\n",
      "7/7 - 0s - loss: -1.5255e+01 - val_loss: -1.7350e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 244/300\n",
      "7/7 - 0s - loss: -1.5327e+01 - val_loss: -1.7491e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 245/300\n",
      "7/7 - 0s - loss: -1.5399e+01 - val_loss: -1.7579e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 246/300\n",
      "7/7 - 0s - loss: -1.5551e+01 - val_loss: -1.7602e+01 - 106ms/epoch - 15ms/step\n",
      "Epoch 247/300\n",
      "7/7 - 0s - loss: -1.5741e+01 - val_loss: -1.7506e+01 - 105ms/epoch - 15ms/step\n",
      "Epoch 248/300\n",
      "7/7 - 0s - loss: -1.5477e+01 - val_loss: -1.7672e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 249/300\n",
      "7/7 - 0s - loss: -1.6033e+01 - val_loss: -1.7807e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 250/300\n",
      "7/7 - 0s - loss: -1.5938e+01 - val_loss: -1.7890e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 251/300\n",
      "7/7 - 0s - loss: -1.5992e+01 - val_loss: -1.7871e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 252/300\n",
      "7/7 - 0s - loss: -1.6368e+01 - val_loss: -1.8061e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 253/300\n",
      "7/7 - 0s - loss: -1.6046e+01 - val_loss: -1.7955e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 254/300\n",
      "7/7 - 0s - loss: -1.6571e+01 - val_loss: -1.8304e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 255/300\n",
      "7/7 - 0s - loss: -1.6913e+01 - val_loss: -1.8275e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 256/300\n",
      "7/7 - 0s - loss: -1.6356e+01 - val_loss: -1.8372e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 257/300\n",
      "7/7 - 0s - loss: -1.6824e+01 - val_loss: -1.8445e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 258/300\n",
      "7/7 - 0s - loss: -1.6916e+01 - val_loss: -1.8464e+01 - 99ms/epoch - 14ms/step\n",
      "Epoch 259/300\n",
      "7/7 - 0s - loss: -1.6567e+01 - val_loss: -1.8575e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 260/300\n",
      "7/7 - 0s - loss: -1.7072e+01 - val_loss: -1.8562e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 261/300\n",
      "7/7 - 0s - loss: -1.7086e+01 - val_loss: -1.8735e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 262/300\n",
      "7/7 - 0s - loss: -1.7369e+01 - val_loss: -1.8779e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 263/300\n",
      "7/7 - 0s - loss: -1.7533e+01 - val_loss: -1.8845e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 264/300\n",
      "7/7 - 0s - loss: -1.7502e+01 - val_loss: -1.8930e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 265/300\n",
      "7/7 - 0s - loss: -1.7450e+01 - val_loss: -1.8961e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 266/300\n",
      "7/7 - 0s - loss: -1.7621e+01 - val_loss: -1.9084e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 267/300\n",
      "7/7 - 0s - loss: -1.7883e+01 - val_loss: -1.9094e+01 - 103ms/epoch - 15ms/step\n",
      "Epoch 268/300\n",
      "7/7 - 0s - loss: -1.7767e+01 - val_loss: -1.9120e+01 - 105ms/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/300\n",
      "7/7 - 0s - loss: -1.7902e+01 - val_loss: -1.9328e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 270/300\n",
      "7/7 - 0s - loss: -1.8002e+01 - val_loss: -1.9198e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 271/300\n",
      "7/7 - 0s - loss: -1.8120e+01 - val_loss: -1.9513e+01 - 92ms/epoch - 13ms/step\n",
      "Epoch 272/300\n",
      "7/7 - 0s - loss: -1.8360e+01 - val_loss: -1.9436e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 273/300\n",
      "7/7 - 0s - loss: -1.8544e+01 - val_loss: -1.9559e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 274/300\n",
      "7/7 - 0s - loss: -1.8105e+01 - val_loss: -1.9633e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 275/300\n",
      "7/7 - 0s - loss: -1.8824e+01 - val_loss: -1.9736e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 276/300\n",
      "7/7 - 0s - loss: -1.8171e+01 - val_loss: -1.9772e+01 - 109ms/epoch - 16ms/step\n",
      "Epoch 277/300\n",
      "7/7 - 0s - loss: -1.8798e+01 - val_loss: -1.9857e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 278/300\n",
      "7/7 - 0s - loss: -1.8689e+01 - val_loss: -1.9850e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 279/300\n",
      "7/7 - 0s - loss: -1.8772e+01 - val_loss: -1.9954e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 280/300\n",
      "7/7 - 0s - loss: -1.9173e+01 - val_loss: -2.0113e+01 - 108ms/epoch - 15ms/step\n",
      "Epoch 281/300\n",
      "7/7 - 0s - loss: -1.9120e+01 - val_loss: -2.0097e+01 - 103ms/epoch - 15ms/step\n",
      "Epoch 282/300\n",
      "7/7 - 0s - loss: -1.9252e+01 - val_loss: -2.0258e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 283/300\n",
      "7/7 - 0s - loss: -1.9328e+01 - val_loss: -2.0184e+01 - 93ms/epoch - 13ms/step\n",
      "Epoch 284/300\n",
      "7/7 - 0s - loss: -1.9040e+01 - val_loss: -1.9896e+01 - 94ms/epoch - 13ms/step\n",
      "Epoch 285/300\n",
      "7/7 - 0s - loss: -1.9437e+01 - val_loss: -1.9928e+01 - 99ms/epoch - 14ms/step\n",
      "Epoch 286/300\n",
      "7/7 - 0s - loss: -1.9721e+01 - val_loss: -2.0033e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 287/300\n",
      "7/7 - 0s - loss: -1.9886e+01 - val_loss: -2.0107e+01 - 105ms/epoch - 15ms/step\n",
      "Epoch 288/300\n",
      "7/7 - 0s - loss: -1.9817e+01 - val_loss: -2.0145e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 289/300\n",
      "7/7 - 0s - loss: -1.9617e+01 - val_loss: -2.0272e+01 - 103ms/epoch - 15ms/step\n",
      "Epoch 290/300\n",
      "7/7 - 0s - loss: -2.0145e+01 - val_loss: -2.0268e+01 - 96ms/epoch - 14ms/step\n",
      "Epoch 291/300\n",
      "7/7 - 0s - loss: -1.9831e+01 - val_loss: -2.0409e+01 - 98ms/epoch - 14ms/step\n",
      "Epoch 292/300\n",
      "7/7 - 0s - loss: -2.0022e+01 - val_loss: -2.0063e+01 - 101ms/epoch - 14ms/step\n",
      "Epoch 293/300\n",
      "7/7 - 0s - loss: -1.9570e+01 - val_loss: -2.0068e+01 - 103ms/epoch - 15ms/step\n",
      "Epoch 294/300\n",
      "7/7 - 0s - loss: -2.0286e+01 - val_loss: -2.0182e+01 - 95ms/epoch - 14ms/step\n",
      "Epoch 295/300\n",
      "7/7 - 0s - loss: -2.0025e+01 - val_loss: -2.0322e+01 - 100ms/epoch - 14ms/step\n",
      "Epoch 296/300\n",
      "7/7 - 0s - loss: -1.9941e+01 - val_loss: -2.0229e+01 - 102ms/epoch - 15ms/step\n",
      "Epoch 297/300\n",
      "7/7 - 0s - loss: -2.0829e+01 - val_loss: -2.0377e+01 - 103ms/epoch - 15ms/step\n",
      "Epoch 298/300\n",
      "7/7 - 0s - loss: -2.0564e+01 - val_loss: -2.0451e+01 - 99ms/epoch - 14ms/step\n",
      "Epoch 299/300\n",
      "7/7 - 0s - loss: -2.1198e+01 - val_loss: -2.0585e+01 - 97ms/epoch - 14ms/step\n",
      "Epoch 300/300\n",
      "7/7 - 0s - loss: -2.0736e+01 - val_loss: -2.0528e+01 - 96ms/epoch - 14ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add (Activation('sigmoid'))\n",
    "\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#model.compile(loss='mae', optimizer='adam')\n",
    "model.compile(loss='BinaryCrossentropy', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X_scaled, train_y, epochs=300, batch_size=200, validation_data=(test_X_scaled, test_y), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ff7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 1, 512)            6539264   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,367,937\n",
      "Trainable params: 7,367,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "136/136 [==============================] - 4s 24ms/step - loss: -1.5530 - binary_crossentropy: -1.5530 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 2/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 3/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 4/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 5/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 6/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 7/30\n",
      "136/136 [==============================] - 3s 23ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 8/30\n",
      "136/136 [==============================] - 3s 23ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 9/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 10/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 11/30\n",
      "136/136 [==============================] - 3s 23ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 12/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 13/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 14/30\n",
      "136/136 [==============================] - 3s 23ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 15/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 16/30\n",
      "136/136 [==============================] - 3s 25ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 17/30\n",
      "136/136 [==============================] - 3s 24ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 18/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 19/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 20/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 21/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 22/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 23/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 24/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 25/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 26/30\n",
      "136/136 [==============================] - 3s 22ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 27/30\n",
      "136/136 [==============================] - 3s 23ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 28/30\n",
      "136/136 [==============================] - 3s 23ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 29/30\n",
      "136/136 [==============================] - 3s 23ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n",
      "Epoch 30/30\n",
      "136/136 [==============================] - 3s 25ms/step - loss: -1.6034 - binary_crossentropy: -1.6034 - val_loss: -2.3541 - val_binary_crossentropy: -2.3541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(512, activation='relu', recurrent_activation='sigmoid', input_shape=(train_X.shape[1], train_X.shape[2]), \n",
    "         return_sequences=True))\n",
    "model.add(LSTM(256, activation='relu', recurrent_activation='sigmoid', return_sequences=False))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1))\n",
    "#model.add(Reshape((train_y.shape[0], train_y.shape[1]))) \n",
    "#model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "#model.compile(loss='BinaryCrossentropy', optimizer='adam')\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='BinaryCrossentropy', metrics=[tf.keras.metrics.BinaryCrossentropy()])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_X_scaled, train_y, epochs=30, batch_size=10, validation_data=(test_X_scaled, test_y), verbose=1, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d779f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd55b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b43962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65673566, 0.63672924, 0.5387803 , ..., 0.57577896, 0.6746322 ,\n",
       "        0.6506463 ],\n",
       "       [0.63323987, 0.61497736, 0.5379125 , ..., 0.55477506, 0.6531005 ,\n",
       "        0.63446313],\n",
       "       [0.5428772 , 0.53399825, 0.49171364, ..., 0.47527534, 0.56892234,\n",
       "        0.55222714],\n",
       "       ...,\n",
       "       [0.57116044, 0.5681766 , 0.39480558, ..., 0.51808405, 0.5922399 ,\n",
       "        0.5582009 ],\n",
       "       [0.36962563, 0.3752942 , 0.3204309 , ..., 0.33458644, 0.39363533,\n",
       "        0.37832975],\n",
       "       [0.52926785, 0.5221544 , 0.377454  , ..., 0.50028616, 0.54115164,\n",
       "        0.5157621 ]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(test_X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "518d8f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e9682ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57c3cc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 1, 2680)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "70a159a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c526320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfce28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "#Getting data\n",
    "ticker = 'TSLA'\n",
    "df_stockData = pdr.DataReader(ticker, data_source='yahoo', start='2012-10-20',\n",
    "                              end=str(date.today() - timedelta(days=1)))\n",
    "#Scaling\n",
    "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "df_stockData_x = scaler_x.fit_transform(df_stockData[selected_features])\n",
    "df_stockData_y = scaler_y.fit_transform(np.array(df_stockData['Close'].values).reshape(-1, 1))\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "df_stockData_x = pca.fit_transform(df_stockData_x)\n",
    "df_stockData_x = MinMaxScaler(feature_range=(0, 1)).fit_transform(df_stockData_x)\n",
    "\n",
    "#Here I omit some code where I just prep my dataset wherein I use past 21 days data to predict next 3 days\n",
    "# so input : 21 days data -> output 3 days close price\n",
    "# Also I use a subset of features, generally 2-3 features (high,low,open etc)\n",
    "\n",
    "\n",
    "# my model\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(512, activation='tanh', recurrent_activation='sigmoid', input_shape=(x_train.shape[1], x_train.shape[2]), \n",
    "         return_sequences=True))\n",
    "model.add(LSTM(256, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Reshape((y_train.shape[1], y_train.shape[2]))) \n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=30, batch_size=5, validation_split=0.3, verbose=1)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
