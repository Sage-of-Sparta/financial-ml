{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "247d14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler # for normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline # pipeline making\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics # for the check the error and accuracy of the model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## for Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, InputLayer, SimpleRNN, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5b946aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Ref: https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80a8417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/20days_supervised.csv')\n",
    "\n",
    "X = pd.read_csv('data/supervised_x_transform.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "677182e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('data/supervised_y_transform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "648ef962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2870</th>\n",
       "      <th>2871</th>\n",
       "      <th>2872</th>\n",
       "      <th>2873</th>\n",
       "      <th>2874</th>\n",
       "      <th>2875</th>\n",
       "      <th>2876</th>\n",
       "      <th>2877</th>\n",
       "      <th>2878</th>\n",
       "      <th>2879</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows × 2880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  2870  \\\n",
       "0      0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
       "1      0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
       "2      0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
       "3      0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0  ...   1.0   \n",
       "4      0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0  ...   0.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "1928   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0  ...   0.0   \n",
       "1929   0.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
       "1930   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1931   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1932   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "      2871  2872  2873  2874  2875  2876  2877  2878  2879  \n",
       "0      0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0  \n",
       "3      0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "1928   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "1929   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "1930   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  \n",
       "1931   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0  \n",
       "1932   0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0  \n",
       "\n",
       "[1933 rows x 2880 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Create an instance of One-hot-encoder\n",
    "enc=OneHotEncoder()\n",
    "\n",
    "#Create an instance of One-hot-encoder\n",
    "#NOTE: we have converted the enc.fit_transform() method to array because the fit_transform method \n",
    "#of OneHotEncoder returns SpiPy sparse matrix this enables us to save space when we \n",
    "#have huge  number of categorical variables\n",
    "\n",
    "enc_data=pd.DataFrame(enc.fit_transform(X[X.columns[(X.columns.str.contains('ret'))]]).toarray())\n",
    "enc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fff86662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spy_volume</th>\n",
       "      <th>spy_volatility_atr</th>\n",
       "      <th>spy_trend_ichimoku_conv</th>\n",
       "      <th>spy_trend_ichimoku_base</th>\n",
       "      <th>spy_trend_ichimoku_a</th>\n",
       "      <th>spy_trend_ichimoku_b</th>\n",
       "      <th>spy_trend_cci</th>\n",
       "      <th>spy_momentum_rsi</th>\n",
       "      <th>spy_trend_macd</th>\n",
       "      <th>spy_trend_macd_signal</th>\n",
       "      <th>...</th>\n",
       "      <th>2870</th>\n",
       "      <th>2871</th>\n",
       "      <th>2872</th>\n",
       "      <th>2873</th>\n",
       "      <th>2874</th>\n",
       "      <th>2875</th>\n",
       "      <th>2876</th>\n",
       "      <th>2877</th>\n",
       "      <th>2878</th>\n",
       "      <th>2879</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.635854</td>\n",
       "      <td>-0.768911</td>\n",
       "      <td>-1.228789</td>\n",
       "      <td>-1.198210</td>\n",
       "      <td>-1.214626</td>\n",
       "      <td>-1.228482</td>\n",
       "      <td>-0.761048</td>\n",
       "      <td>-0.428784</td>\n",
       "      <td>-0.179188</td>\n",
       "      <td>-0.049984</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.334445</td>\n",
       "      <td>-0.569042</td>\n",
       "      <td>-1.224474</td>\n",
       "      <td>-1.195734</td>\n",
       "      <td>-1.211228</td>\n",
       "      <td>-1.228482</td>\n",
       "      <td>-0.208049</td>\n",
       "      <td>0.123715</td>\n",
       "      <td>-0.122793</td>\n",
       "      <td>-0.066005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827986</td>\n",
       "      <td>-0.631394</td>\n",
       "      <td>-1.224474</td>\n",
       "      <td>-1.195734</td>\n",
       "      <td>-1.211228</td>\n",
       "      <td>-1.228482</td>\n",
       "      <td>-0.150884</td>\n",
       "      <td>-0.123819</td>\n",
       "      <td>-0.100438</td>\n",
       "      <td>-0.074012</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.253428</td>\n",
       "      <td>-0.682698</td>\n",
       "      <td>-1.224474</td>\n",
       "      <td>-1.195734</td>\n",
       "      <td>-1.211228</td>\n",
       "      <td>-1.228482</td>\n",
       "      <td>0.097455</td>\n",
       "      <td>0.072373</td>\n",
       "      <td>-0.063809</td>\n",
       "      <td>-0.072537</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.430273</td>\n",
       "      <td>-0.763005</td>\n",
       "      <td>-1.224474</td>\n",
       "      <td>-1.195734</td>\n",
       "      <td>-1.211228</td>\n",
       "      <td>-1.228482</td>\n",
       "      <td>0.120501</td>\n",
       "      <td>-0.040461</td>\n",
       "      <td>-0.045494</td>\n",
       "      <td>-0.067416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>-0.173857</td>\n",
       "      <td>1.169231</td>\n",
       "      <td>1.285575</td>\n",
       "      <td>1.193637</td>\n",
       "      <td>1.240783</td>\n",
       "      <td>1.116198</td>\n",
       "      <td>0.842632</td>\n",
       "      <td>0.718795</td>\n",
       "      <td>1.580745</td>\n",
       "      <td>1.470431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>-0.242454</td>\n",
       "      <td>1.146990</td>\n",
       "      <td>1.285575</td>\n",
       "      <td>1.193637</td>\n",
       "      <td>1.240783</td>\n",
       "      <td>1.116198</td>\n",
       "      <td>0.722470</td>\n",
       "      <td>0.673401</td>\n",
       "      <td>1.629908</td>\n",
       "      <td>1.527443</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>-0.297206</td>\n",
       "      <td>1.201621</td>\n",
       "      <td>1.288615</td>\n",
       "      <td>1.193637</td>\n",
       "      <td>1.242329</td>\n",
       "      <td>1.116198</td>\n",
       "      <td>0.275733</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>1.486505</td>\n",
       "      <td>1.542198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>-0.046944</td>\n",
       "      <td>1.240065</td>\n",
       "      <td>1.280724</td>\n",
       "      <td>1.193637</td>\n",
       "      <td>1.238319</td>\n",
       "      <td>1.116198</td>\n",
       "      <td>-0.451813</td>\n",
       "      <td>-0.440507</td>\n",
       "      <td>1.228233</td>\n",
       "      <td>1.498431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>-0.646185</td>\n",
       "      <td>1.161578</td>\n",
       "      <td>1.280724</td>\n",
       "      <td>1.193637</td>\n",
       "      <td>1.238319</td>\n",
       "      <td>1.116198</td>\n",
       "      <td>-0.793762</td>\n",
       "      <td>-0.491026</td>\n",
       "      <td>0.995047</td>\n",
       "      <td>1.413244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows × 5190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spy_volume  spy_volatility_atr  spy_trend_ichimoku_conv  \\\n",
       "0       0.635854           -0.768911                -1.228789   \n",
       "1       2.334445           -0.569042                -1.224474   \n",
       "2       0.827986           -0.631394                -1.224474   \n",
       "3       1.253428           -0.682698                -1.224474   \n",
       "4      -0.430273           -0.763005                -1.224474   \n",
       "...          ...                 ...                      ...   \n",
       "1928   -0.173857            1.169231                 1.285575   \n",
       "1929   -0.242454            1.146990                 1.285575   \n",
       "1930   -0.297206            1.201621                 1.288615   \n",
       "1931   -0.046944            1.240065                 1.280724   \n",
       "1932   -0.646185            1.161578                 1.280724   \n",
       "\n",
       "      spy_trend_ichimoku_base  spy_trend_ichimoku_a  spy_trend_ichimoku_b  \\\n",
       "0                   -1.198210             -1.214626             -1.228482   \n",
       "1                   -1.195734             -1.211228             -1.228482   \n",
       "2                   -1.195734             -1.211228             -1.228482   \n",
       "3                   -1.195734             -1.211228             -1.228482   \n",
       "4                   -1.195734             -1.211228             -1.228482   \n",
       "...                       ...                   ...                   ...   \n",
       "1928                 1.193637              1.240783              1.116198   \n",
       "1929                 1.193637              1.240783              1.116198   \n",
       "1930                 1.193637              1.242329              1.116198   \n",
       "1931                 1.193637              1.238319              1.116198   \n",
       "1932                 1.193637              1.238319              1.116198   \n",
       "\n",
       "      spy_trend_cci  spy_momentum_rsi  spy_trend_macd  spy_trend_macd_signal  \\\n",
       "0         -0.761048         -0.428784       -0.179188              -0.049984   \n",
       "1         -0.208049          0.123715       -0.122793              -0.066005   \n",
       "2         -0.150884         -0.123819       -0.100438              -0.074012   \n",
       "3          0.097455          0.072373       -0.063809              -0.072537   \n",
       "4          0.120501         -0.040461       -0.045494              -0.067416   \n",
       "...             ...               ...             ...                    ...   \n",
       "1928       0.842632          0.718795        1.580745               1.470431   \n",
       "1929       0.722470          0.673401        1.629908               1.527443   \n",
       "1930       0.275733          0.009021        1.486505               1.542198   \n",
       "1931      -0.451813         -0.440507        1.228233               1.498431   \n",
       "1932      -0.793762         -0.491026        0.995047               1.413244   \n",
       "\n",
       "      ...  2870  2871  2872  2873  2874  2875  2876  2877  2878  2879  \n",
       "0     ...   1.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "1     ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "2     ...   1.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0  \n",
       "3     ...   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "4     ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0  \n",
       "...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "1928  ...   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "1929  ...   1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "1930  ...   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  \n",
       "1931  ...   0.0   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0  \n",
       "1932  ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0  \n",
       "\n",
       "[1933 rows x 5190 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[X.columns[(~X.columns.str.contains('ret'))]]\n",
    "X\n",
    "\n",
    "X=X.join(enc_data)\n",
    "  \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "da71cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3\n",
       "0    0.00 0.00 0.00 1.00\n",
       "1    0.00 1.00 0.00 0.00\n",
       "2    0.00 0.00 1.00 0.00\n",
       "3    0.00 1.00 0.00 0.00\n",
       "4    0.00 1.00 0.00 0.00\n",
       "...   ...  ...  ...  ...\n",
       "1928 0.00 0.00 0.00 1.00\n",
       "1929 1.00 0.00 0.00 0.00\n",
       "1930 1.00 0.00 0.00 0.00\n",
       "1931 0.00 0.00 1.00 0.00\n",
       "1932 0.00 0.00 1.00 0.00\n",
       "\n",
       "[1933 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(enc.fit_transform(y).toarray())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "12607695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('supervised_x_transform_onehot.csv',index=False)\n",
    "y.to_csv('supervised_y_transform_onehot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6dae9e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3\n",
       "0    0.00 0.00 0.00 1.00\n",
       "1    0.00 1.00 0.00 0.00\n",
       "2    0.00 0.00 1.00 0.00\n",
       "3    0.00 1.00 0.00 0.00\n",
       "4    0.00 1.00 0.00 0.00\n",
       "...   ...  ...  ...  ...\n",
       "1928 0.00 0.00 0.00 1.00\n",
       "1929 1.00 0.00 0.00 0.00\n",
       "1930 1.00 0.00 0.00 0.00\n",
       "1931 0.00 0.00 1.00 0.00\n",
       "1932 0.00 0.00 1.00 0.00\n",
       "\n",
       "[1933 rows x 4 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6bec6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier, LazyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6e51025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                   | 1/29 [00:08<03:56,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for AdaBoostClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                 | 2/29 [00:16<03:42,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for BaggingClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▏                                                              | 3/29 [00:17<02:02,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for BernoulliNB\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████▋                                                            | 4/29 [00:33<03:57,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for CalibratedClassifierCV\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████                                                          | 5/29 [00:34<02:28,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB model failed to execute\n",
      "Negative values in data passed to CategoricalNB (input X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██████████████▍                                                       | 6/29 [00:35<01:45,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for DecisionTreeClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|████████████████▉                                                     | 7/29 [00:36<01:10,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for DummyClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████▎                                                  | 8/29 [00:36<00:48,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for ExtraTreeClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████▋                                                | 9/29 [00:38<00:43,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for ExtraTreesClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████▊                                             | 10/29 [00:38<00:31,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for GaussianNB\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████▏                                          | 11/29 [00:39<00:23,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for KNeighborsClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████▌                                        | 12/29 [00:40<00:19,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for LabelPropagation\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████████████████▉                                      | 13/29 [00:40<00:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for LabelSpreading\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|█████████████████████████████████▎                                   | 14/29 [00:43<00:23,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for LinearDiscriminantAnalysis\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|███████████████████████████████████▋                                 | 15/29 [00:49<00:39,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for LinearSVC\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████████████████████                               | 16/29 [00:50<00:29,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for LogisticRegression\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████▍                            | 17/29 [00:50<00:20,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for NearestCentroid\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████▊                          | 18/29 [01:02<00:52,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for NuSVC\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████▏                       | 19/29 [01:04<00:39,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for PassiveAggressiveClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████▌                     | 20/29 [01:05<00:28,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for Perceptron\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████▉                   | 21/29 [01:06<00:19,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for QuadraticDiscriminantAnalysis\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████▎                | 22/29 [01:08<00:15,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for RandomForestClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|██████████████████████████████████████████████████████▋              | 23/29 [01:09<00:10,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for RidgeClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|█████████████████████████████████████████████████████████            | 24/29 [01:09<00:07,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for RidgeClassifierCV\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|███████████████████████████████████████████████████████████▍         | 25/29 [01:11<00:05,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for SGDClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████▊       | 26/29 [01:24<00:14,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for SVC\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "StackingClassifier model failed to execute\n",
      "__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|██████████████████████████████████████████████████████████████████▌  | 28/29 [01:35<00:05,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for XGBClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 29/29 [01:42<00:00,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for LGBMClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
      "Model                                                                          \n",
      "XGBClassifier                      0.37               0.36    None      0.37   \n",
      "LGBMClassifier                     0.35               0.33    None      0.35   \n",
      "LogisticRegression                 0.34               0.33    None      0.34   \n",
      "NuSVC                              0.34               0.33    None      0.34   \n",
      "SGDClassifier                      0.33               0.32    None      0.33   \n",
      "AdaBoostClassifier                 0.35               0.32    None      0.34   \n",
      "RandomForestClassifier             0.34               0.32    None      0.33   \n",
      "NearestCentroid                    0.33               0.32    None      0.33   \n",
      "BaggingClassifier                  0.32               0.31    None      0.33   \n",
      "KNeighborsClassifier               0.32               0.31    None      0.30   \n",
      "PassiveAggressiveClassifier        0.32               0.31    None      0.32   \n",
      "ExtraTreesClassifier               0.33               0.31    None      0.33   \n",
      "Perceptron                         0.32               0.31    None      0.32   \n",
      "SVC                                0.35               0.31    None      0.32   \n",
      "LinearSVC                          0.32               0.31    None      0.31   \n",
      "GaussianNB                         0.33               0.30    None      0.32   \n",
      "RidgeClassifierCV                  0.32               0.30    None      0.31   \n",
      "RidgeClassifier                    0.31               0.30    None      0.31   \n",
      "BernoulliNB                        0.32               0.30    None      0.32   \n",
      "DecisionTreeClassifier             0.30               0.30    None      0.30   \n",
      "LinearDiscriminantAnalysis         0.30               0.29    None      0.30   \n",
      "ExtraTreeClassifier                0.29               0.28    None      0.29   \n",
      "DummyClassifier                    0.34               0.25    None      0.18   \n",
      "LabelSpreading                     0.19               0.25    None      0.06   \n",
      "LabelPropagation                   0.19               0.25    None      0.06   \n",
      "QuadraticDiscriminantAnalysis      0.24               0.24    None      0.24   \n",
      "CalibratedClassifierCV             0.27               0.23    None      0.21   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "XGBClassifier                       11.45  \n",
      "LGBMClassifier                       6.91  \n",
      "LogisticRegression                   0.92  \n",
      "NuSVC                               11.93  \n",
      "SGDClassifier                        1.31  \n",
      "AdaBoostClassifier                   8.46  \n",
      "RandomForestClassifier               1.83  \n",
      "NearestCentroid                      0.40  \n",
      "BaggingClassifier                    8.06  \n",
      "KNeighborsClassifier                 0.47  \n",
      "PassiveAggressiveClassifier          2.15  \n",
      "ExtraTreesClassifier                 1.93  \n",
      "Perceptron                           1.11  \n",
      "SVC                                 12.87  \n",
      "LinearSVC                            5.73  \n",
      "GaussianNB                           0.48  \n",
      "RidgeClassifierCV                    0.70  \n",
      "RidgeClassifier                      0.49  \n",
      "BernoulliNB                          0.52  \n",
      "DecisionTreeClassifier               1.46  \n",
      "LinearDiscriminantAnalysis           3.03  \n",
      "ExtraTreeClassifier                  0.36  \n",
      "DummyClassifier                      0.35  \n",
      "LabelSpreading                       0.63  \n",
      "LabelPropagation                     0.74  \n",
      "QuadraticDiscriminantAnalysis        0.92  \n",
      "CalibratedClassifierCV              16.89  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y),test_size=.3,random_state =123)\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=False, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "339acbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=9e-07, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=9e-07, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=9e-07, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y),test_size=.1,random_state =123)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "#clf = OneVsRestClassifier(XGBClassifier(n_jobs=-1))\n",
    "clf = XGBClassifier(n_jobs=-1,learning_rate=0.0000009)\n",
    "clf.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef7913b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction\n",
    "y_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1baf02b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "950495aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (y_test == y_pred)\n",
    "pd.DataFrame(test).to_csv('testresult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "89607507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d68626a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d80230a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1933, 3030)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a135fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1933, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4c209a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353, 3030) (1353,) (580, 3030) (580,)\n",
      "(1353, 1, 3030) (1353,) (580, 1, 3030) (580,)\n",
      "(1353, 1, 3030) (1353, 1) (580, 1, 3030) (580, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "#\n",
    "\n",
    "n_train_time = round(X.shape[0] * 0.7)\n",
    "train_X = X.iloc[:n_train_time, :].values\n",
    "test_X = X.iloc[n_train_time:, :].values\n",
    "train_y = X.iloc[:n_train_time, 0].values\n",
    "test_y = X.iloc[n_train_time:, 0].values\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#scaler = StandardScaler()\n",
    "train_X_scale = scaler.fit_transform(train_X)\n",
    "test_X_scale = scaler.fit_transform(test_X)\n",
    "\n",
    "train_y_scale = scaler.fit_transform(train_y.reshape(-1, 1))\n",
    "test_y_scale = scaler.fit_transform(test_y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "train_X_scale = train_X_scale.reshape((train_X_scale.shape[0], 1, train_X_scale.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "test_X_scale = test_X_scale.reshape((test_X_scale.shape[0], 1, test_X_scale.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "print(train_X_scale.shape, train_y_scale.shape, test_X_scale.shape, test_y_scale.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87b89e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.        ,  1.        ,  0.63585437, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 3.        ,  1.        ,  2.33444492, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 1.        ,  1.        ,  0.82798609, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.        ,  1.        , -0.69092124, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 2.        ,  2.        , -1.35690892, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  2.        , -0.34154828, ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed4013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7507b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 - 3s - loss: 7.9453 - accuracy: 0.1567 - val_loss: 8.1114 - val_accuracy: 0.2517 - 3s/epoch - 40ms/step\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 995ms/epoch - 15ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 999ms/epoch - 15ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1000ms/epoch - 15ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 998ms/epoch - 15ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 999ms/epoch - 15ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 999ms/epoch - 15ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 7.9918 - accuracy: 0.1589 - val_loss: 8.1114 - val_accuracy: 0.2517 - 1s/epoch - 15ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Dense(1))\n",
    "#model.add (Activation('sigmoid'))\n",
    "\n",
    "\n",
    "#model.add(LSTM(100, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#model.compile(loss='mae', optimizer='adam')\n",
    "#model.compile(loss='BinaryCrossentropy', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X_scale, train_y_scale, epochs=20, batch_size=20, validation_data=(test_X_scale, test_y_scale), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90ff7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 32)                98016     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,049\n",
      "Trainable params: 98,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "136/136 [==============================] - 1s 1ms/step - loss: -0.7098 - binary_crossentropy: -0.7098\n",
      "Epoch 2/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -1.9304 - binary_crossentropy: -1.9304\n",
      "Epoch 3/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -2.9761 - binary_crossentropy: -2.9761\n",
      "Epoch 4/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -4.0226 - binary_crossentropy: -4.0226\n",
      "Epoch 5/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -5.0891 - binary_crossentropy: -5.0891\n",
      "Epoch 6/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -6.1723 - binary_crossentropy: -6.1723\n",
      "Epoch 7/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -7.2676 - binary_crossentropy: -7.2676\n",
      "Epoch 8/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -8.3716 - binary_crossentropy: -8.3716\n",
      "Epoch 9/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -9.4821 - binary_crossentropy: -9.4821\n",
      "Epoch 10/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -10.5978 - binary_crossentropy: -10.5978\n",
      "Epoch 11/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -11.7174 - binary_crossentropy: -11.7174\n",
      "Epoch 12/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -12.8402 - binary_crossentropy: -12.8402\n",
      "Epoch 13/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -13.9656 - binary_crossentropy: -13.9656\n",
      "Epoch 14/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -15.0931 - binary_crossentropy: -15.0931\n",
      "Epoch 15/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -16.2224 - binary_crossentropy: -16.2224\n",
      "Epoch 16/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -17.3531 - binary_crossentropy: -17.3531\n",
      "Epoch 17/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -18.4851 - binary_crossentropy: -18.4851\n",
      "Epoch 18/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -19.6182 - binary_crossentropy: -19.6182\n",
      "Epoch 19/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -20.7521 - binary_crossentropy: -20.7521\n",
      "Epoch 20/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -21.8868 - binary_crossentropy: -21.8868\n",
      "Epoch 21/30\n",
      "136/136 [==============================] - 0s 2ms/step - loss: -23.0222 - binary_crossentropy: -23.0222\n",
      "Epoch 22/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -24.1581 - binary_crossentropy: -24.1581\n",
      "Epoch 23/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -25.2945 - binary_crossentropy: -25.2945\n",
      "Epoch 24/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -26.4312 - binary_crossentropy: -26.4312\n",
      "Epoch 25/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -27.5684 - binary_crossentropy: -27.5684\n",
      "Epoch 26/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -28.7059 - binary_crossentropy: -28.7059\n",
      "Epoch 27/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -29.8436 - binary_crossentropy: -29.8436\n",
      "Epoch 28/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -30.9815 - binary_crossentropy: -30.9815\n",
      "Epoch 29/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -32.1197 - binary_crossentropy: -32.1197\n",
      "Epoch 30/30\n",
      "136/136 [==============================] - 0s 1ms/step - loss: -33.2580 - binary_crossentropy: -33.2580\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = Sequential()\n",
    "#model.add(\n",
    "#    LSTM(512, activation='sigmoid', input_shape=(train_X.shape[1], train_X.shape[2]), \n",
    "#         return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(1))\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(SimpleRNN(units=32, input_shape=(train_X.shape[1], train_X.shape[2]),activation='sigmoid'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "          \n",
    "model.compile(optimizer=Adam(), loss='BinaryCrossentropy', metrics=[tf.keras.metrics.BinaryCrossentropy()])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=30, batch_size=10, verbose=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d4a12bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 1, 100)            1252400   \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1, 128)            12928     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1, 64)             8256      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1, 1)              65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,273,649\n",
      "Trainable params: 1,273,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "136/136 [==============================] - 2s 8ms/step - loss: -8.3772 - binary_crossentropy: -8.3772 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 2/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 3/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 4/30\n",
      "136/136 [==============================] - 1s 7ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 5/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 6/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 7/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 8/30\n",
      "136/136 [==============================] - 1s 8ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 9/30\n",
      "136/136 [==============================] - 1s 7ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 10/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 11/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 12/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 13/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 14/30\n",
      "136/136 [==============================] - 1s 7ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 15/30\n",
      "136/136 [==============================] - 1s 7ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 16/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 17/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 18/30\n",
      "136/136 [==============================] - 1s 7ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 19/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 20/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 21/30\n",
      "136/136 [==============================] - 1s 7ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 22/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 23/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 24/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 25/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 26/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 27/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 28/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 29/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n",
      "Epoch 30/30\n",
      "136/136 [==============================] - 1s 6ms/step - loss: -8.4530 - binary_crossentropy: -8.4530 - val_loss: -8.8077 - val_binary_crossentropy: -8.8077\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(100, activation='sigmoid', recurrent_activation='sigmoid', input_shape=(train_X.shape[1], train_X.shape[2]), \n",
    "         return_sequences=True))\n",
    "#model.add(LSTM(256, activation='sigmoid', recurrent_activation='sigmoid', return_sequences=False))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1))\n",
    "#model.add(Reshape((train_y.shape[0], train_y.shape[1]))) \n",
    "#model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "#model.compile(loss='BinaryCrossentropy', optimizer='adam')\n",
    "\n",
    "#model.compile(optimizer=Adam(learning_rate=0.0001), loss='BinaryCrossentropy', metrics=[tf.keras.metrics.BinaryCrossentropy()])\n",
    "model.compile(optimizer=Adam(), loss='BinaryCrossentropy', metrics=[tf.keras.metrics.BinaryCrossentropy()])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=30, batch_size=10, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d779f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd55b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b43962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65673566, 0.63672924, 0.5387803 , ..., 0.57577896, 0.6746322 ,\n",
       "        0.6506463 ],\n",
       "       [0.63323987, 0.61497736, 0.5379125 , ..., 0.55477506, 0.6531005 ,\n",
       "        0.63446313],\n",
       "       [0.5428772 , 0.53399825, 0.49171364, ..., 0.47527534, 0.56892234,\n",
       "        0.55222714],\n",
       "       ...,\n",
       "       [0.57116044, 0.5681766 , 0.39480558, ..., 0.51808405, 0.5922399 ,\n",
       "        0.5582009 ],\n",
       "       [0.36962563, 0.3752942 , 0.3204309 , ..., 0.33458644, 0.39363533,\n",
       "        0.37832975],\n",
       "       [0.52926785, 0.5221544 , 0.377454  , ..., 0.50028616, 0.54115164,\n",
       "        0.5157621 ]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(test_X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "518d8f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e9682ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57c3cc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 1, 2680)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "70a159a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c526320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfce28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "#Getting data\n",
    "ticker = 'TSLA'\n",
    "df_stockData = pdr.DataReader(ticker, data_source='yahoo', start='2012-10-20',\n",
    "                              end=str(date.today() - timedelta(days=1)))\n",
    "#Scaling\n",
    "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "df_stockData_x = scaler_x.fit_transform(df_stockData[selected_features])\n",
    "df_stockData_y = scaler_y.fit_transform(np.array(df_stockData['Close'].values).reshape(-1, 1))\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "df_stockData_x = pca.fit_transform(df_stockData_x)\n",
    "df_stockData_x = MinMaxScaler(feature_range=(0, 1)).fit_transform(df_stockData_x)\n",
    "\n",
    "#Here I omit some code where I just prep my dataset wherein I use past 21 days data to predict next 3 days\n",
    "# so input : 21 days data -> output 3 days close price\n",
    "# Also I use a subset of features, generally 2-3 features (high,low,open etc)\n",
    "\n",
    "\n",
    "# my model\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(512, activation='tanh', recurrent_activation='sigmoid', input_shape=(x_train.shape[1], x_train.shape[2]), \n",
    "         return_sequences=True))\n",
    "model.add(LSTM(256, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Reshape((y_train.shape[1], y_train.shape[2]))) \n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=30, batch_size=5, validation_split=0.3, verbose=1)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a868e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, InputLayer, SimpleRNN, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "132a97a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train),(X_test, y_test) = mnist.load_data() \n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d2eb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(SimpleRNN(units=32, input_shape=(X_train.shape[1:]), activation=\"relu\"))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3ea63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.9138 - accuracy: 0.6892 - val_loss: 0.5834 - val_accuracy: 0.8162\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5228 - accuracy: 0.8431 - val_loss: 0.4914 - val_accuracy: 0.8434\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4199 - accuracy: 0.8781 - val_loss: 0.3791 - val_accuracy: 0.8872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f79a355610>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00075a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 9s 1us/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      " 15/391 [>.............................] - ETA: 10:57 - loss: 0.6926 - accuracy: 0.5115"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Final evaluation of the model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Programs\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Programs\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2a1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
